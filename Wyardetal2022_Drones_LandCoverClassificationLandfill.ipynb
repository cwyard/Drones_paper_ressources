{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This processing chain is available under [Creative Common Licence (CC-BY)](https://creativecommons.org/licenses/by/4.0/), so feel free to re-use, adapt or enhance it to match your own needs. \n",
    "\n",
    "![alt text](https://i.creativecommons.org/l/by/4.0/88x31.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This processing chain is a result of the CETEO research (ISSeP, Moerman's fund, 2019-2022): https://www.issep.be/wp-content/uploads/Projet-CETEO.pdf\n",
    "\n",
    "It is an adaptation of the work of Grippa et al. (2017): Grippa T, Lennert M, Beaumont B, Vanhuysse S, Stephenne N, Wolff E. An Open-Source Semi-Automated Processing Chain for Urban Object-Based Classification. Remote Sensing. 2017; 9(4):358. https://doi.org/10.3390/rs9040358\n",
    "\n",
    "Original code can be downloaded on the following GitHub repository: https://github.com/tgrippa/Opensource_OBIA_processing_chain\n",
    "\n",
    "It includes code modification inspired from: Stefanos Georganos, Tais Grippa, Sabine Vanhuysse, Moritz Lennert, Michal Shimoni, Stamatis Kalogirou & Eleonore Wolff (2018) Less is more: optimizing classification performance through feature selection in a very-high-resolution remote sensing object-based urban application, GIScience & Remote Sensing, 55:2, 221-242, DOI: 10.1080/15481603.2017.1408892"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation guide for OSGEO4W"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Dowload OSGEO4W from https://trac.osgeo.org/osgeo4w/ and copy it on a secondary disk (e.g. D or E) \n",
    "2. Launch 'osgeo4w-setup.exe' as an administrator\n",
    "3. Choose 'Advanced Install'\n",
    "           'Install from Local Directory'\n",
    "\n",
    "            Root Directory: C:\\OSGeo4W\n",
    "            (x) All Users (RECOMENDED)\n",
    "            [x] Add icon to Start Menu\n",
    "\n",
    "Local Package Directory == 'E:\\OSGeo4W_install\\OSGeo4L\\AppData\\Local\\Temp'\n",
    "                           (To be adapted according to 'OSGeo4W_install' folder)\n",
    "\n",
    "4. Click on \"All\" components to be installed > install status appears for each component\n",
    "5. Click \"next\"\n",
    "            [x] I agree with above license terms\n",
    "            (for each module to be installed)\n",
    "\n",
    "6. Restart windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insallation guide for JupyterLab"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use the OSGEO4W Python version by launching the following commands from the OSGEO4w Shell: \n",
    "  python -m pip install --trusted-host pypi.org --upgrade pip\n",
    "  pip install jupyter\n",
    "  pip install ipykernel\n",
    "  pip install jupyter_client\n",
    "  pip install nbconvert\n",
    "  pip install jupyterlab\n",
    "\n",
    "\n",
    "To laucnh jupyter-lab from the OSGeo4W Shell:\n",
    "  jupyter-lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are used to: \n",
    "- Import needed libraries\n",
    "- Set the environment variables for Python, Anaconda, GRASS GIS and R statistical computing \n",
    "- Define the [\"GRASSDATA\" folder](https://grass.osgeo.org/grass73/manuals/helptext.html), the name of \"location\" and \"mapset\" where you want to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries needed for setting parameters of operating system\n",
    "import os\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "## Import libraries for temporary files creation\n",
    "import tempfile\n",
    "\n",
    "## Import Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "## Import Numpy library\n",
    "import numpy as np\n",
    "\n",
    "## Import subprocess\n",
    "import subprocess\n",
    "\n",
    "## Import mutiprocess\n",
    "import multiprocessing\n",
    "\n",
    "## Import Matplotlib for creating graphs\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "## agg backend is used to create plot as a .png file\n",
    "mpl.use('agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set 'Python' and 'GRASS GIS' environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check is environmental variables exists and create them (empty) if not exists.\n",
    "if not 'PYTHONPATH' in os.environ:\n",
    "    os.environ['PYTHONPATH']=''\n",
    "if not 'LD_LIBRARY_PATH' in os.environ:\n",
    "    os.environ['LD_LIBRARY_PATH']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change XXX ti your username folder\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "dossierDeBase = r'C:\\OSGeo4W'\n",
    "\n",
    "grass7bin_win = join(dossierDeBase,'bin','grass78.bat') \n",
    "\n",
    "os.environ['GISBASE'] = join(dossierDeBase,'apps','grass','grass78')\n",
    "\n",
    "os.environ['PATH'] = join(dossierDeBase,'apps','grass','grass78','lib')\n",
    "os.environ['PATH'] = join(dossierDeBase,'apps','grass','grass78','bin') + os.pathsep + os.environ['PATH']\n",
    "os.environ['PATH'] = join(dossierDeBase,'apps','grass','grass78','etc') + os.pathsep + os.environ['PATH']\n",
    "os.environ['PATH'] = join(dossierDeBase,'apps','grass','grass78','etc','python') + os.pathsep + os.environ['PATH']\n",
    "os.environ['PATH'] = join(dossierDeBase,'bin') + os.pathsep + os.environ['PATH']\n",
    "\n",
    "# Chemin vers les fichiers \"scripts\" spécifiques\n",
    "os.environ['PATH'] = join(r'C:\\Users','XXX','AppData','Roaming','GRASS7','addons','scripts') + os.pathsep + os.environ['PATH']\n",
    "os.environ['GIS_LOCK'] = '$$'\n",
    "os.environ['GISRC'] = join(r'C:\\Users','XXX','AppData','Roaming','GRASS7','rc')\n",
    "os.environ['GDAL_DATA'] = join(dossierDeBase,'share','gdal')\n",
    "print(os.environ['PATH'])\n",
    "\n",
    "## Define GRASS Python environment\n",
    "sys.path.append(os.path.join(os.environ['GISBASE'],'etc','python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set 'R statistical computing software' environment variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we set [the environment variables allowing to use the R statistical computing software](https://stat.ethz.ch/R-manual/R-devel/library/base/html/EnvVar.html) inside this Jupyter notebook. Please change the directory path to match your system configuration. If you are working on Windows, the paths below should be similar. \n",
    "\n",
    "Please notice that you will probably have to set the path of R_LIBS_USER also directly in R interface. For that, open R software (or [Rstudio software](https://www.rstudio.com/)) and enter the following command in the command prompt (you should adapt this path to match your own configuration: **.libPaths('C:\\\\R_LIBS_USER\\\\win-library\\\\4.1.1')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add the R software directory to the general PATH\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "os.environ['PATH'] = r'C:\\Program Files\\R\\R-4.1.1\\bin' + os.pathsep + os.environ['PATH']\n",
    "\n",
    "## Set R stat environment variables\n",
    "os.environ['R_HOME'] = r'C:\\Program Files\\R\\R-4.1.1'\n",
    "os.environ['R_ENVIRON'] = r'C:\\Program Files\\R\\R-4.1.1\\etc\\x64'\n",
    "os.environ['R_DOC_DIR'] = r'C:\\Program Files\\R\\R-4.1.1\\doc'\n",
    "os.environ['R_LIBS'] = r'C:\\Program Files\\R\\R-4.1.1\\library'\n",
    "os.environ['R_LIBS_USER'] = r'C:\\R_LIBS_USER\\win-library\\4.1.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display current environment variables of your computer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================== Display current environment variables ===============================\n",
    "for key in os.environ.keys ():\n",
    "    print(\"%s = %s \\t\" %(key,os.environ[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define an empty dictionnary for saving user inputs\n",
    "user={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after:\n",
    "- Enter the path to the directory you want to use as \"[GRASSDATA](https://grass.osgeo.org/programming7/loc_struct.png)\". \n",
    "- Enter the name of the location in which you want to work and its projection information in [EPSG code](http://spatialreference.org/ref/epsg/) format. Please note that the GRASSDATA folder and locations will be automatically created if they do not yet exist. If the location name already exists, the projection information will not be used.  \n",
    "- Enter the name you want for the mapsets which will be used later for Unsupervised Segmentation Parameter Optimization (USPO), Segmentation and Classification steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enter the path to GRASSDATA folder\n",
    "\n",
    "DossierGRASSDATA = 'D:\\\\' \n",
    "user[\"gisdb\"] = join(DossierGRASSDATA,'XXX')\n",
    "\n",
    "## Enter the name of the location/sector\n",
    "user[\"location\"] = \"XXX\"\n",
    "\n",
    "## Enter the EPSG code for this location\n",
    "user[\"locationepsg\"] = \"XXX\" \n",
    "\n",
    "## Enter the name of the mapset to use for the segmentation step\n",
    "user[\"segmentation_mapsetname\"] = \"SEGMENTATION\"\n",
    "\n",
    "## Enter the name of the mapset to use for the classification step\n",
    "user[\"classification_mapsetname\"] = \"CLASSIFICATION\"\n",
    "\n",
    "## Enter the maximum number of processes to run in parallel\n",
    "user[\"nb_proc\"] = 8 #maximum 12-2 CPU \n",
    "\n",
    "if user[\"nb_proc\"] > multiprocessing.cpu_count():\n",
    "    print(\"The required number of cores is higher than the amount available. Please fix it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the GRASSDATA folder and create GRASS location and mapsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after, the python script will check if the GRASSDATA folder, locations and mapsets already exist. If not, they will be automatically created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import GRASS Python packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraires needed to lauch GRASS GIS in Jupyter notebook\n",
    "import grass.script.setup as gsetup #core.py a été modifié suivant https://stackoverflow.com/questions/52269281/fix-import-error-on-using-environb-in-python\n",
    "\n",
    "## Import libraires needed to call GRASS using Python\n",
    "import grass.script as grass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define GRASSDATA folder and create location and mapsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Automatic creation of GRASSDATA folder\n",
    "if os.path.exists(user['gisdb']):\n",
    "    print(\"GRASSDATA folder already exists\")\n",
    "else:\n",
    "    os.makedirs(user['gisdb'])\n",
    "    print(\"GRASSDATA folder created in \"+user['gisdb'])\n",
    "\n",
    "## Automatic creation of GRASS location/sector if it doesn't exist\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"])):\n",
    "    print(\"Location \"+user[\"location\"]+\" already exists\")\n",
    "else :\n",
    "    if sys.platform.startswith('win'):\n",
    "        grass7bin = grass7bin_win\n",
    "        startcmd = grass7bin + ' -c epsg:' + user[\"locationepsg\"] + ' -e ' + os.path.join(user[\"gisdb\"],user[\"location\"])\n",
    "        p = subprocess.Popen(startcmd, shell=True,stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        out, err = p.communicate()\n",
    "        if p.returncode != 0:\n",
    "            print('ERROR: %s' % err,file=sys.stderr)\n",
    "            print('ERROR: Cannot generate location (%s)' % startcmd,file=sys.stderr)\n",
    "            sys.exit(-1)\n",
    "            # If it didn't work, open GRASS and create a GRASS Sector manually using a georeferenced file.\n",
    "        else:\n",
    "            print('Created location %s' % os.path.join(user[\"gisdb\"],user[\"location\"]))\n",
    "    else:\n",
    "        print('This notebook was developed for use with Windows. It seems you are using another OS.')\n",
    "\n",
    "### Automatic creation of GRASS GIS mapsets\n",
    "## Import library for file copying\n",
    "import shutil\n",
    "\n",
    "## SEGMENTATION mapset\n",
    "mapsetname=user[\"segmentation_mapsetname\"]\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname)):\n",
    "    print(\"'\"+mapsetname+\"' mapset already exists\")\n",
    "else:\n",
    "    os.makedirs(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname))\n",
    "    shutil.copy(os.path.join(user[\"gisdb\"],user[\"location\"],'PERMANENT','WIND'),\\\n",
    "                os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname,'WIND'))\n",
    "    print(\"'\"+mapsetname+\"' mapset created in location \"+user[\"gisdb\"])\n",
    "## CLASSIFICATION mapset\n",
    "mapsetname=user[\"classification_mapsetname\"]\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname)):\n",
    "    print(\"'\"+mapsetname+\"' mapset already exists\")\n",
    "else:\n",
    "    os.makedirs(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname))\n",
    "    shutil.copy(os.path.join(user[\"gisdb\"],user[\"location\"],'PERMANENT','WIND'), \\\n",
    "                os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname,'WIND'))\n",
    "    print(\"'\"+mapsetname+\"' mapset created in location \"+user[\"gisdb\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (optionnal) Load functions if not installed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Launch GRASS GIS working session in the PERMANENT mapset\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],\"PERMANENT\")):\n",
    "    gsetup.init(os.environ['GISBASE'], user[\"gisdb\"], user[\"location\"], \"PERMANENT\")\n",
    "    print (\"You are now working in mapset 'PERMANENT'\") \n",
    "else: \n",
    "    print (\"'PERMANENT' mapset doesn't exists in \"+user[\"gisdb\"])\n",
    "\n",
    "## In cas g.extension is not properly working. Go to https://wingrass.fsv.cvut.cz/grass78/x86_64/addons/ to download the right versions of addons (stored in .zip). Be sure to remove prior versions to avoid conflict.\n",
    "\n",
    "## Instal r.neighborhoodmatrix if not yet installed\n",
    "if \"r.neighborhoodmatrix\" not in grass.parse_command('g.extension', flags=\"a\"):\n",
    "    grass.run_command('g.extension', extension=\"r.neighborhoodmatrix\")\n",
    "    print (\"r.neighborhoodmatrix have been installed on your computer\")\n",
    "else: print (\"r.neighborhoodmatrix is already installed on your computer\") \n",
    "\n",
    "## Instal i.segment.hierarchical if not yet installed\n",
    "if \"i.segment.hierarchical\" not in grass.parse_command('g.extension', flags=\"a\"):\n",
    "    grass.run_command('g.extension', extension=\"i.segment.hierarchical\")\n",
    "    print (\"i.segment.hierarchical have been installed on your computer\")\n",
    "else: print (\"i.segment.hierarchical is already installed on your computer\")\n",
    "\n",
    "## Instal i.segment.uspo if not yet installed\n",
    "if \"i.segment.uspo\" not in grass.parse_command('g.extension', flags=\"a\"):\n",
    "    grass.run_command('g.extension', extension=\"i.segment.uspo\")\n",
    "    print (\"i.segment.uspo have been installed on your computer\")\n",
    "else: print (\"i.segment.uspo is already installed on your computer\")\n",
    "    \n",
    "## Instal i.segment.stats if not yet installed\n",
    "if \"i.segment.stats\" not in grass.parse_command('g.extension', flags=\"a\"):\n",
    "    grass.run_command('g.extension', extension=\"i.segment.stats\")\n",
    "    print (\"i.segment.stats have been installed on your computer\")\n",
    "else: print (\"i.segment.stats is already installed on your computer\") \n",
    "    \n",
    "## Instal r.object.geometry if not yet installed\n",
    "if \"r.object.geometry\" not in grass.parse_command('g.extension', flags=\"a\"):\n",
    "    grass.run_command('g.extension', extension=\"r.object.geometry\")\n",
    "    print (\"r.object.geometry have been installed on your computer\")\n",
    "else: print (\"r.object.geometry is already installed on your computer\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for computing processing time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"print_processing_time\" function is used to calculate and display the processing time for various stages of the processing chain. At the beginning of each major step, the current time is stored in a new variable, using [time.time() function](https://docs.python.org/2/library/time.html). At the end of the stage in question, the \"print_processing_time\" function is called and takes as an argument, the name of this new variable containing the recorded time at the beginning of the stage, and an output message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import library for managing time in python\n",
    "import time\n",
    "\n",
    "## Function \"print_processing_time()\" compute processing time and print it.\n",
    "# The argument \"begintime\" wait for a variable containing the begintime \n",
    "#(result of time.time()) of the process for which to compute processing time.\n",
    "# The argument \"printmessage\" wait for a string format with information about the process.\n",
    "def print_processing_time(begintime, printmessage):\n",
    "    endtime=time.time()\n",
    "    processtime=endtime-begintime\n",
    "    remainingtime=processtime\n",
    "    days=int((remainingtime)/86400)\n",
    "    remainingtime-=(days*86400)\n",
    "    hours=int((remainingtime)/3600)\n",
    "    remainingtime-=(hours*3600)\n",
    "    minutes=int((remainingtime)/60)\n",
    "    remainingtime-=(minutes*60)\n",
    "    seconds=round((remainingtime)%60,1)\n",
    "    if processtime<60:\n",
    "        finalprintmessage=str(printmessage)+str(seconds)+\" seconds\"\n",
    "    elif processtime<3600:\n",
    "        finalprintmessage=str(printmessage)+str(minutes)+\" minutes and \"+str(seconds)+\" seconds\"\n",
    "    elif processtime<86400:\n",
    "        finalprintmessage=str(printmessage)+str(hours)+\" hours and \"+str(minutes)+\" minutes and \"+str(seconds)+\" seconds\"\n",
    "    elif processtime>=86400:\n",
    "        finalprintmessage=str(printmessage)+str(days)+\" days, \"+str(hours)+\" hours and \"+str(minutes)+\" minutes and \"+str(seconds)+\" seconds\"\n",
    "    return finalprintmessage\n",
    "\n",
    "## Saving current time for processing time management\n",
    "begintime_full=time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, original data are imported and stored in the \"PERMANENT\" mapset (automatically created when creating a new location)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Launch GRASS GIS working session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the name of the mapset in which to import the data\n",
    "mapsetname='PERMANENT'\n",
    "\n",
    "## Launch GRASS GIS working session in the mapset\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname)):\n",
    "    gsetup.init(os.environ['GISBASE'], user[\"gisdb\"], user[\"location\"],mapsetname)\n",
    "    print(\"You are now working in mapset '\"+mapsetname+\"'\")\n",
    "else:\n",
    "    print(\"'\"+mapsetname+\"' mapset doesn't exists in \"+user[\"gisdb\"])\n",
    "\n",
    "## Saving current time for processing time management\n",
    "begintime_full=time.time()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import raw data in PERMANENT mapset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import optical raster imagery "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please adapt the number of lines in the loop to match the number of layers stacked in your imagery file (ensuring the number of ['g.rename' commands](https://grass.osgeo.org/grass73/manuals/g.rename.html) equal the number of layers stacked). Ensure the names of the layers match their position in the stack (e.g. \"opt_blue\" for the first layer).\n",
    "\n",
    "Please note that it is assumed that your data has at least a red band layer, called \"opt_red\". If not, you will have to change several parameters through this notebook, notably when defining [computation region](https://grasswiki.osgeo.org/wiki/Computational_region). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== Import optical raster imagery ===\n",
    "\n",
    "## Saving current time for processing time management\n",
    "begintime_optical=time.time()\n",
    "\n",
    "## Import optical imagery and rename band with color name\n",
    "print(\"Importing optical raster imagery at \" + time.ctime())\n",
    "grass.run_command('r.in.gdal',input=r'XXX:\\XXX\\RGB.tif', \\\n",
    "                  output='optical', overwrite=True, flags = 'o')\n",
    "\n",
    "for rast in grass.list_strings(\"rast\"):\n",
    "    print(\"toto4\")\n",
    "    if rast.find(\"1\")!=-1: grass.run_command(\"g.rename\", overwrite=True,rast=(rast,\"opt_red\"))\n",
    "    elif rast.find(\"2\")!=-1: grass.run_command(\"g.rename\", overwrite=True,rast=(rast,\"opt_green\"))\n",
    "    elif rast.find(\"3\")!=-1: grass.run_command(\"g.rename\", overwrite=True,rast=(rast,\"opt_blue\"))\n",
    "    #elif rast.find(\"\")!=-1: grass.run_command(\"g.rename\", overwrite=True,rast=(rast,\"opt_nir\"))\n",
    "    \n",
    "print_processing_time(begintime_optical ,\"Optical imagery has been imported in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check in GRASS the optical rasters and setnull if needed\n",
    "grass.run_command('r.null', map=\"opt_red@PERMANENT\", setnull=\"0\") # 0 values in the rasters will be associated to null\n",
    "grass.run_command('r.null', map=\"opt_green@PERMANENT\", setnull=\"0\")\n",
    "grass.run_command('r.null', map=\"opt_blue@PERMANENT\", setnull=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the name of rasters available in PERMANENT\n",
    "print(grass.list_strings(\"raster\", mapset=\"PERMANENT\", flag='r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import nDSM raster imagery (if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have null value in your nDSM raster, please be careful to define the \"setnull\" parameter of ['r.null' command](https://grass.osgeo.org/grass73/manuals/r.null.html) well, according to your own data. If you didn't have any null values in your nDSM raster, simply comment the r.null command line with an '#' as first character (to put it in [comment](http://www.pythonforbeginners.com/comments/comments-in-python)). Notice that you can display the line's number by pressing the L key when cell edge is in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_ndsm=time.time()\n",
    "\n",
    "## Import nDSM imagery\n",
    "print(\"Importing nDSM raster imagery at \" + time.ctime())\n",
    "grass.run_command('r.in.gdal', input=r'XXX:\\XXX\\RGB1_dsm_Clip.tif', \\\n",
    "                              output=\"DSM\", overwrite=True, flags = 'o')\n",
    "\n",
    "## Define null value for specific value in nDSM raster. Adapt the value to your own data.\n",
    "# If there is no null value in your data, comment the next line\n",
    "grass.run_command('r.null', map=\"DSM\", setnull=\"-9999\")\n",
    "\n",
    "print_processing_time(begintime_ndsm, \"DSM has been imported in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update imagery group \"optical\" with optical rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In GRASS GIS several operations, mainly segmentation when dealing with OBIA, require an 'imagery group'.\n",
    "\n",
    "In the next cell, a new imagery group called 'optical' containing the optical raster layers is created with ['i.group command'](https://grass.osgeo.org/grass73/manuals/i.group.html). It is impossible to create a new imagery group, if the name already exists, therefore existing imagery groups with the same name are removed (with ['g.remove command'](https://grass.osgeo.org/grass73/manuals/g.remove.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Updating imagery group 'optical' with optical rasters at \" + time.ctime())\n",
    "\n",
    "## Remove existing imagery group nammed \"optical\". This group was created when importing multilayer raster data\n",
    "grass.run_command(\"g.remove\", type=\"group\", name=\"optical\", flags=\"f\")\n",
    "\n",
    "## Add each raster which begin with the prefix \"opt\" into a new imagery group \"optical\"\n",
    "for rast in grass.list_strings(\"rast\", pattern=\"opt\", flag=\"r\"):\n",
    "    grass.run_command(\"i.group\", group=\"optical\", input=rast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save default GRASS GIS' computational region for the whole extent of optical imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In GRASS GIS, the concept of computational region is fundamental. We highly recommend reading [information about the computation region in GRASS GIS](https://grasswiki.osgeo.org/wiki/Computational_region) to be sure to understand the concept. \n",
    "\n",
    "Here after, the 'default' computational region is defined as corresponding to the red band image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save default computational region to match the full extend of optical imagery\n",
    "grass.run_command('g.region', flags=\"s\", raster=\"opt_red@PERMANENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute pseudo-band raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set computational region and mask layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ['r.mask' command](https://grass.osgeo.org/grass73/manuals/r.mask.html) is used not to perform further processing on 'nodata' pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set computational region to default\n",
    "grass.run_command('g.region', flags=\"d\")\n",
    "\n",
    "## Apply mask to not compute out-of-AOI pixels \n",
    "grass.run_command('r.mask', overwrite=True, raster=\"opt_red@PERMANENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Slope, NDVI, NDWI, Brightness, Angular second texture indices according to the input data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begintime_importingdata=time.time()\n",
    "\n",
    "## Saving current time for processing time management\n",
    "print (\"Begin compute SLOPE on \"+time.ctime())\n",
    "begintime_slope=time.time()\n",
    "\n",
    "## Compute SLOPE\n",
    "grass.run_command('r.slope.aspect', overwrite=True, elevation=\"nDSM@PERMANENT\", slope=\"SLOPE\", aspect=\"SLOPE_ASPECT\")\n",
    "print_processing_time(begintime_slope, \"Slope has been computed in \")\n",
    "\n",
    "## Saving current time for processing time management\n",
    "print (\"Begin compute NDVI on \"+time.ctime())\n",
    "begintime_ndvi=time.time()\n",
    "\n",
    "## Compute NDVI\n",
    "formula=\"NDVI=(float(opt_nir@PERMANENT)-float(opt_red@PERMANENT))/ \\\n",
    "           (float(opt_nir@PERMANENT)+float(opt_red@PERMANENT))\"\n",
    "\n",
    "grass.mapcalc(formula, overwrite=True)\n",
    "print_processing_time(begintime_ndvi, \"NDVI has been computed in \")\n",
    "\n",
    "# Saving current time for processing time management\n",
    "print (\"Begin compute NDWI on \"+time.ctime())\n",
    "begintime_ndwi=time.time()\n",
    "\n",
    "## Compute NDWI\n",
    "formula=\"NDWI=(float(opt_green@PERMANENT)-float(opt_nir@PERMANENT))/ \\\n",
    "           (float(opt_green@PERMANENT)+float(opt_nir@PERMANENT))\"\n",
    "\n",
    "grass.mapcalc(formula, overwrite=True)\n",
    "print_processing_time(begintime_ndwi, \"NDWI has been computed in \")\n",
    "\n",
    "# Saving current time for processing time management\n",
    "print (\"Begin compute brightness on \"+time.ctime())\n",
    "begintime_brightness=time.time()\n",
    "\n",
    "## Compute Brightness\n",
    "formula=\"Brightness=opt_blue@PERMANENT+opt_green@PERMANENT+opt_red@PERMANENT\"\n",
    "grass.mapcalc(formula, overwrite=True)\n",
    "\n",
    "print_processing_time(begintime_brightness, \"Brightness has been computed in \")\n",
    "\n",
    "## Check if there is a raster layer named \"MASK\"\n",
    "if not grass.list_strings(\"rast\", pattern=\"MASK\", flag='r'):\n",
    "    print('There is currently no MASK')\n",
    "else:\n",
    "## Remove the current MASK layer\n",
    "    grass.run_command('r.mask',flags='r')\n",
    "    print('The current MASK has been removed')\n",
    "\n",
    "print(\"Importation of data ends at \"+ time.ctime())\n",
    "print_processing_time(begintime_importingdata, \"Importation of data has been achieved in :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove all NULL values in rasters\n",
    "grass.run_command('r.null', map=\"SLOPE@PERMANENT\", null=\"-9999\")\n",
    "grass.run_command('r.null', map=\"SLOPE_ASPECT@PERMANENT\", null=\"-9999\")\n",
    "grass.run_command('r.null', map=\"NDWI@PERMANENT\", null=\"-9999\")\n",
    "grass.run_command('r.null', map=\"NDVI@PERMANENT\", null=\"-9999\")\n",
    "grass.run_command('r.null', map=\"Brightness@PERMANENT\", null=\"-9999\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute pseudo-panchromatic band and texture files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPUTE PSEUDO PANCHROMATIC BAND\n",
    "\n",
    "## Saving current time for processing time management\n",
    "print (\"Begin compute pseudo_panchro levels on \"+time.ctime())\n",
    "begintime_panchro=time.time()\n",
    "\n",
    "grass.run_command('g.region', overwrite=True, raster=\"opt_red@PERMANENT\")\n",
    "\n",
    "#grass.mapcalc(formula, overwrite=True)\n",
    "formula=\"pseudo_panchro01 = 0.2989 * opt_red@PERMANENT + 0.5870 * opt_green@PERMANENT + 0.1140 * opt_blue@PERMANENT\"\n",
    "grass.mapcalc(formula, overwrite=True)\n",
    "\n",
    "print_processing_time(begintime_panchro, \"Pseudo panchromatic band has been computed in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPUTE TEXTURE ON PANCHROMATIC BAND\n",
    "## Apply mask to not compute out-of-AOI- pixels\n",
    "grass.run_command('r.mask', overwrite=True, raster=\"opt_red@PERMANENT\")\n",
    "\n",
    "## Saving current time for processing time management\n",
    "print (\"Begin compute Texture P on \"+time.ctime())\n",
    "begintime_texturep=time.time()\n",
    "\n",
    "## Compute texture\n",
    "grass.run_command('r.texture', overwrite='True', input=\"pseudo_panchro01@PERMANENT\",output=\"texture_P_15\", method=\"sa\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"pseudo_panchro01@PERMANENT\",output=\"texture_P_15\", method=\"asm\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"pseudo_panchro01@PERMANENT\",output=\"texture_P_15\", method=\"idm\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"pseudo_panchro01@PERMANENT\",output=\"texture_P_15\", method=\"se\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"pseudo_panchro01@PERMANENT\",output=\"texture_P_15\", method=\"dv\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"pseudo_panchro01@PERMANENT\",output=\"texture_P_15\", method=\"entr\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"pseudo_panchro01@PERMANENT\",output=\"texture_P_15\", method=\"corr\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"pseudo_panchro01@PERMANENT\",output=\"texture_P_15\", method=\"contr\", size=\"15\")\n",
    "\n",
    "print_processing_time(begintime_texturep, \"Texture P has been computed in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPUTE TEXTURE ON GREEN BAND\n",
    "\n",
    "## Saving current time for processing time management\n",
    "print (\"Begin compute Texture G on \"+time.ctime())\n",
    "begintime_textureg=time.time()\n",
    "\n",
    "## Compute texture\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_green@PERMANENT\",output=\"texture_G_15\", method=\"sa\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_green@PERMANENT\",output=\"texture_G_15\", method=\"asm\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_green@PERMANENT\",output=\"texture_G_15\", method=\"idm\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_green@PERMANENT\",output=\"texture_G_15\", method=\"se\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_green@PERMANENT\",output=\"texture_G_15\", method=\"dv\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_green@PERMANENT\",output=\"texture_G_15\", method=\"entr\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_green@PERMANENT\",output=\"texture_G_15\", method=\"corr\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_green@PERMANENT\",output=\"texture_G_15\", method=\"contr\", size=\"15\")\n",
    "\n",
    "print_processing_time(begintime_textureg, \"Texture Ghas been computed in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPUTE TEXTURE ON BLUE BAND\n",
    "\n",
    "## Saving current time for processing time management\n",
    "print (\"Begin compute Texture B on \"+time.ctime())\n",
    "begintime_textureb=time.time()\n",
    "\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_blue@PERMANENT\",output=\"texture_B_15\", method=\"sa\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_blue@PERMANENT\",output=\"texture_B_15\", method=\"asm\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_blue@PERMANENT\",output=\"texture_B_15\", method=\"idm\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_blue@PERMANENT\",output=\"texture_B_15\", method=\"se\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_blue@PERMANENT\",output=\"texture_B_15\", method=\"dv\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_blue@PERMANENT\",output=\"texture_B_15\", method=\"entr\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_blue@PERMANENT\",output=\"texture_B_15\", method=\"corr\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_blue@PERMANENT\",output=\"texture_B_15\", method=\"contr\", size=\"15\")\n",
    "\n",
    "print_processing_time(begintime_textureb, \"Texture B has been computed in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPUTE TEXTURE ON RED BAND\n",
    "\n",
    "## Saving current time for processing time management\n",
    "print (\"Begin compute Texture R on \"+time.ctime())\n",
    "begintime_texturer=time.time()\n",
    "\n",
    "## Compute texture\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_red@PERMANENT\",output=\"texture_R_15\", method=\"sa\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_red@PERMANENT\",output=\"texture_R_15\", method=\"asm\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_red@PERMANENT\",output=\"texture_R_15\", method=\"idm\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_red@PERMANENT\",output=\"texture_R_15\", method=\"se\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_red@PERMANENT\",output=\"texture_R_15\", method=\"dv\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_red@PERMANENT\",output=\"texture_R_15\", method=\"entr\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_red@PERMANENT\",output=\"texture_R_15\", method=\"corr\", size=\"15\")\n",
    "grass.run_command('r.texture', overwrite='True', input=\"opt_red@PERMANENT\",output=\"texture_R_15\", method=\"contr\", size=\"15\")\n",
    "\n",
    "print_processing_time(begintime_textureb, \"Texture R has been computed in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the name of rasters available in PERMANENT and CLASSIFICATION mapsets\n",
    "print(grass.list_strings(\"raster\", mapset=\"PERMANENT\", flag='r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove current mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if there is a raster layer named \"MASK\"\n",
    "if not grass.list_strings(\"rast\", pattern=\"MASK\", flag='r'):\n",
    "    print('There is currently no MASK')\n",
    "else:\n",
    "## Remove the current MASK layer\n",
    "    grass.run_command('r.mask',flags='r')\n",
    "    print('The current MASK has been removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Importation of data ends at \"+ time.ctime())\n",
    "print_processing_time(begintime_importingdata, \"Importation of data has been achieved in :\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**\n",
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Launch GRASS GIS working session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the name of the mapset in which to work\n",
    "mapsetname=user[\"segmentation_mapsetname\"]\n",
    "\n",
    "## Launch GRASS GIS working session in the mapset\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname)):\n",
    "    gsetup.init(os.environ['GISBASE'], user[\"gisdb\"], user[\"location\"],mapsetname)\n",
    "    print(\"You are now working in mapset '\"+mapsetname+\"'\")\n",
    "else:\n",
    "    print(\"'\"+mapsetname+\"' mapset doesn't exists in \"+user[\"gisdb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of raster available in CLASSIFICATION mapset\n",
    "grass.list_strings('raster', mapset='SEGMENTATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_segmentation_full=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Save default computational region to match the full extend of optical imagery\n",
    "grass.run_command('g.region', flags=\"s\", raster=\"opt_red@PERMANENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a group with raster used for segmentation\n",
    "\n",
    "## Saving current time for processing time management\n",
    "begintime_segmentation_full=time.time()\n",
    "print(\"Defining a imagery group with raster used for segmentation at \" +time.ctime())\n",
    "\n",
    "# GROUP 1\n",
    "# Remove existing imagery group named \"group\"\n",
    "grass.run_command('g.remove', flags=\"rf\", type=\"group\", name=\"group1\")\n",
    "\n",
    "# Add all optical imagery in the imagery group\n",
    "grass.run_command('i.group', group=\"group1\", input=\"opt_red@PERMANENT\")\n",
    "grass.run_command('i.group', group=\"group1\", input=\"opt_green@PERMANENT\")\n",
    "grass.run_command('i.group', group=\"group1\", input=\"opt_blue@PERMANENT\")\n",
    "\n",
    "# list files in the group\n",
    "print(grass.read_command('i.group', group=\"group1\", flags=\"l\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1  : i.segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Begin segmentation process on \" + time.ctime())\n",
    "## Saving current time for processing time management\n",
    "begintime_segmentation=time.time()\n",
    "\n",
    "grass.run_command('i.segment', overwrite=True, group=\"group1\", \\\n",
    "           output=\"segments_20\", threshold=0.06, minsize=\"20\",memory=\"10000\")\n",
    "\n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_segmentation, \"Segmentation process achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 : i.superpixels.slic + i.segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install i.superpixels.slic if not yet installed\n",
    "\n",
    "if \"i.superpixels.slic\" not in grass.parse_command('g.extension', flags=\"a\"):\n",
    "    grass.run_command('g.extension', extension=\"i.superpixels.slic\")\n",
    "    print (\"i.superpixels.slic have been installed on your computer\")\n",
    "else: print (\"i.superpixels.slic is already installed on your computer\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Begin segmentation process on \" + time.ctime())\n",
    "\n",
    "## Saving current time for processing time management\n",
    "begintime_superpixels=time.time()\n",
    "\n",
    "grass.run_command('g.region', flags='d')\n",
    "print('toto1')\n",
    "grass.run_command('r.mask', overwrite=True, raster=\"opt_red@PERMANENT\")\n",
    "print('toto2')\n",
    "\n",
    "grass.run_command('i.superpixels.slic', overwrite=True, input=\"group1\", \\\n",
    "           iterations='10', compactness=\"0.05\", minsize=\"10\", num_pixels = \"5000000\", output=\"superpixels_1\", memory=\"10000\")\n",
    "\n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_superpixels, \"Superpixels process achieved in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Begin segmentation process on \" + time.ctime())\n",
    "\n",
    "## Saving current time for processing time management\n",
    "begintime_segmentation=time.time()\n",
    "\n",
    "## Segmentation using default parameter\n",
    "grass.run_command('i.segment', overwrite=True, group=\"group1\", seeds=\"superpixels_1\", \\\n",
    "           output=\"segments_01\", threshold=0.1, minsize=\"2\",memory=\"10000\")\n",
    "\n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_segmentation, \"Segmentation process achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The script ends at \"+ time.ctime())\n",
    "print_processing_time(begintime_segmentation_full, \"Entire process has been achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**\n",
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3 - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Launch GRASS GIS working session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the name of the mapset in which to work\n",
    "mapsetname=user[\"classification_mapsetname\"]\n",
    "\n",
    "## Launch GRASS GIS working session in the mapset\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname)):\n",
    "    gsetup.init(os.environ['GISBASE'], user[\"gisdb\"], user[\"location\"],mapsetname)\n",
    "    print(\"You are now working in mapset '\"+mapsetname+\"'\")\n",
    "else:\n",
    "    print(\"'\"+mapsetname+\"' mapset doesn't exists in \"+user[\"gisdb\"])\n",
    "    \n",
    "## Saving current time for processing time management\n",
    "begintime_classif_full=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy data from other mapset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data need to be copied from other mapsets into the current mapset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy segmentation raster in the current mapset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Copy segmentation raster layer from SEGMENTATION mapset to current mapset\n",
    "grass.run_command('g.copy',overwrite=True,raster='segments_20@SEGMENTATION,segments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy input raster from PERMANENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy DSM raster layer from PERMANENT mapset to current mapset\n",
    "grass.run_command('g.copy', overwrite=True, raster=\"DSM@PERMANENT,DSM\")\n",
    "grass.run_command('r.null', map=\"DSM@CLASSIFICATION\", null=\"-9999\")\n",
    "\n",
    "## Copy SLOPE raster layer from PERMANENT mapset to current mapset\n",
    "grass.run_command('g.copy', overwrite=True, raster=\"SLOPE@PERMANENT,SLOPE\")\n",
    "grass.run_command('r.null', map=\"SLOPE@CLASSIFICATION\", null=\"-9999\")\n",
    "\n",
    "## Copy Brightness raster layer from PERMANENT mapset to current mapset\n",
    "grass.run_command('g.copy', overwrite=True, raster=\"Brightness@PERMANENT,Brightness\")\n",
    "grass.run_command('r.null', map=\"Brightness@CLASSIFICATION\", null=\"-9999\")\n",
    "\n",
    "## Copy NDVI raster layer from PERMANENT mapset to current mapset\n",
    "#grass.run_command('g.copy', overwrite=True, raster=\"NDVI@PERMANENT,NDVI\")\n",
    "#grass.run_command('r.null', map=\"NDVI@CLASSIFICATION\", null=\"-9999\")\n",
    "\n",
    "## Copy NDWI raster layer from PERMANENT mapset to current mapset\n",
    "#grass.run_command('g.copy', overwrite=True, raster=\"NDWI@PERMANENT,NDWI\")\n",
    "#grass.run_command('r.null', map=\"NDWI@CLASSIFICATION\", null=\"-9999\")\n",
    "\n",
    "# Copy Texture raster layer from PERMANENT mapset to current mapset\n",
    "grass.run_command('g.copy', overwrite=True, raster=\"texture_B_15_SA@PERMANENT,texture_B_sa\")\n",
    "grass.run_command('r.null', map=\"texture_B_sa@CLASSIFICATION\", null=\"-9999\")\n",
    "grass.run_command('g.copy', overwrite=True, raster=\"texture_G_15_SA@PERMANENT,texture_G_sa\")\n",
    "grass.run_command('r.null', map=\"texture_G_sa@CLASSIFICATION\", null=\"-9999\")\n",
    "grass.run_command('g.copy', overwrite=True, raster=\"texture_R_15_SA@PERMANENT,texture_R_sa\")\n",
    "grass.run_command('r.null', map=\"texture_R_sa@CLASSIFICATION\", null=\"-9999\")\n",
    "# Include all texture file in the same way\n",
    "\n",
    "# Copy OPTICAL raster layer from PERMANENT mapset to current mapset\n",
    "grass.run_command('g.copy', overwrite=True, raster=\"opt_red@PERMANENT,opt_red\")\n",
    "grass.run_command('g.copy', overwrite=True, raster=\"opt_green@PERMANENT,opt_green\")\n",
    "grass.run_command('g.copy', overwrite=True, raster=\"opt_blue@PERMANENT,opt_blue\")\n",
    "grass.run_command('r.null', map=\"opt_red@CLASSIFICATION\", null=\"-9999\")\n",
    "grass.run_command('r.null', map=\"opt_green@CLASSIFICATION\", null=\"-9999\")\n",
    "grass.run_command('r.null', map=\"opt_blue@CLASSIFICATION\", null=\"-9999\")\n",
    "\n",
    "print(grass.list_strings('all', mapset=mapsetname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of raster available in CLASSIFICATION mapset\n",
    "print (grass.list_strings(\"raster\", mapset=\"CLASSIFICATION\", flag='r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of training/validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A : creation of training and test set from existing global samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set computational region to match the default region\n",
    "grass.run_command('g.region', flags=\"d\")\n",
    "\n",
    "## Import sample data (points)\n",
    "grass.run_command('v.in.ogr', overwrite=True, input=r'E:\\CETEO\\INPUT_PAPIER\\SamplesRGB.shp', output='samples')\n",
    "\n",
    "## Print\n",
    "print(\"Point sample imported on \"+time.ctime())\n",
    "\n",
    "# Saving current time for processing time management\n",
    "print (\"Start building training set on \" + time.ctime())\n",
    "begintime_trainingset=time.time()\n",
    "\n",
    "## Set the ratio of available sample to select for training (between 0 and 1)\n",
    "#ratio=0.5\n",
    "\n",
    "## or set the number of training samples per class\n",
    "nbrextract=70\n",
    "\n",
    "## Set the column containing the class number\n",
    "Class_num = \"Level2\"\n",
    "\n",
    "## Erase potential existing vector\n",
    "grass.run_command('g.remove', flags=\"rf\", type=\"vector\", pattern=\"temp_sample_\")\n",
    "grass.run_command('g.remove', flags=\"rf\", type=\"vector\", pattern=\"training_\")\n",
    "grass.run_command('g.remove', flags=\"rf\", type=\"vector\", pattern=\"training_set\")\n",
    "\n",
    "## Loop through all class label\n",
    "for classnum in grass.parse_command('v.db.select', map='samples', columns=Class_num, flags='c'):\n",
    "    \n",
    "    ## Extract one vector layer per class\n",
    "    condition=\"\"+str(Class_num)+\" = \" +str(classnum)\n",
    "    print(condition)\n",
    "    tempvectorname=\"temp_sample_\"+str(classnum)\n",
    "    grass.run_command('v.extract', overwrite=True, input=\"samples\", type=\"point\", where=condition, output=tempvectorname)\n",
    "\n",
    "    ## Extract class-based training sample (one for each class layer)\n",
    "    nbravailable=grass.vector_info(tempvectorname).points\n",
    "\n",
    "    #nbrextract=int(nbravailable*ratio)\n",
    "    outputname=\"training_class\"+classnum\n",
    "    grass.run_command('v.extract', overwrite=True, input=tempvectorname, output=outputname, type=\"point\", random=nbrextract)\n",
    "    print(str(nbrextract)+\" training samples extracted from the \"+str(nbravailable)+\" available for class '\"+str(classnum)+\"'\")\n",
    "    grass.run_command('g.remove', flags=\"f\", type=\"vector\", name=tempvectorname)\n",
    "\n",
    "## Setting the list of vector to be patched\n",
    "\n",
    "inputlayers=grass.list_strings(\"vector\", pattern=\"training_class\", mapset=mapsetname, flag='r')[0]\n",
    "print(inputlayers)\n",
    "\n",
    "count=1\n",
    "\n",
    "for vect in grass.list_strings(\"vector\", pattern=\"training_class\", mapset=mapsetname, flag='r')[1:]:\n",
    "    inputlayers+=\",\"+vect\n",
    "    count+=1\n",
    "print(inputlayers)\n",
    "\n",
    "\n",
    "## Patch of class-based trainings samples in one unique training set\n",
    "grass.run_command('g.remove', flags=\"f\", type=\"vector\", name=\"training_set\")\n",
    "grass.run_command('v.patch', flags=\"ne\", overwrite=True, input=inputlayers, output=\"training_set\")\n",
    "print(str(count)+\" vector layers patched in one unique training set\")\n",
    "\n",
    "## Erase individual class-based training sample\n",
    "for vect in grass.list_strings(\"vector\", pattern=\"training_class\", mapset=mapsetname, flag='r'):\n",
    "    grass.run_command('g.remove', flags=\"f\", type=\"vector\", name=vect)\n",
    "\n",
    "\n",
    "## Save number of records in the training set\n",
    "nbtraining=len(grass.parse_command('v.db.select', map='training_set', columns='ID', flags='c'))\n",
    "\n",
    "## Print number of records in the training set and processing time\n",
    "print(str(nbtraining)+\" points in the training set\")\n",
    "\n",
    "print_processing_time(begintime_trainingset, \"Training set build in \")\n",
    "\n",
    "## Saving current time for processing time management\n",
    "print (\"Start building test set on \" + time.ctime())\n",
    "begintime_testset=time.time()\n",
    "\n",
    "## Erase existing vector\n",
    "grass.run_command('g.remove', flags=\"rf\", type=\"vector\", pattern=\"test_set\")\n",
    "\n",
    "## Save the id of training point\n",
    "list_id=[]\n",
    "for point_id in grass.parse_command('v.db.select', map='training_set', columns='ID', flags='c'):\n",
    "    list_id.append(str(point_id))\n",
    "\n",
    "## Build SQL statement for 'v.extract' command\n",
    "condition=\"Id not in (\"+str(list_id[0])\n",
    "for point_id in list_id[1:]:\n",
    "    condition+=\",\"+str(point_id)\n",
    "condition+=\")\"\n",
    "    \n",
    "## From sample point, extract point not yet selected in training set\n",
    "grass.run_command('g.remove', flags=\"f\", type=\"vector\", name=\"test_set\")\n",
    "grass.run_command('v.extract', overwrite=True, input=\"samples\", type=\"point\", where=condition, output=\"test_set\")\n",
    "\n",
    "## Save number of records in the test set\n",
    "nbvalidation=len(grass.parse_command('v.db.select', map='test_set', columns='ID', flags='c'))\n",
    "\n",
    "## Print number of records in the test set and processing time\n",
    "print(str(nbvalidation)+\" points in the test set\")\n",
    "print_processing_time(begintime_testset, \"Test set build in \")\n",
    "\n",
    "print(grass.list_strings('vector', mapset=mapsetname))\n",
    "\n",
    "## Export training and test sets in shapefile\n",
    "\n",
    "grass.run_command('v.out.ogr', input='training_set', type='point', output=r'xxx\\TRAINING_RGB_'+str(nbrextract)+'.shp', format='ESRI_Shapefile', overwrite='true')\n",
    "grass.run_command('v.out.ogr', input='test_set', type='point', output=r'xxx\\TEST_RGB_'+str(nbrextract)+'.shp', format='ESRI_Shapefile', overwrite='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2 : import existing training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Erase existing vector\n",
    "grass.run_command('g.remove', flags=\"rf\", type=\"vector\", pattern=\"test_set\")\n",
    "grass.run_command('g.remove', flags=\"rf\", type=\"vector\", pattern=\"training_set\")\n",
    "\n",
    "## Import vector shapefile with the training set\n",
    "grass.run_command('v.in.ogr', overwrite=True, flags ='o', \\\n",
    "    input=r'xxx\\TRAINING_RGB_70.shp', output='training_set')\n",
    "\n",
    "nbtraining=len(grass.parse_command('v.db.select', map='training_set', columns='ID', flags='c'))\n",
    "print(str(nbtraining)+\" points in the training set\")\n",
    "\n",
    "## Import vector shapefile with the test set\n",
    "grass.run_command('v.in.ogr', overwrite=True, flags ='o', \\\n",
    "    input=r'xxx\\TEST_RGB_70.shp', output='test_set')\n",
    "nbvalidation=len(grass.parse_command('v.db.select', map='test_set', columns='ID', flags='c'))\n",
    "print(str(nbvalidation)+\" points in the validation set\")\n",
    "\n",
    "print(grass.list_strings('vector', mapset=mapsetname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify which segment correspond to each training point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our processing chain, the training and test sets are formed of points. However, objects are needed to train the supervised classification in OBIA context. In this section, each point in the training set is used to identify the underlying object in the segmentation layer, and save its unique ID. We use the ['v.db.addcolumn' command](https://grass.osgeo.org/grass72/manuals/v.db.addcolumn.html), ['v.what.rast' command](https://grass.osgeo.org/grass72/manuals/v.what.rast.html) for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encodings\n",
    "print(\"Encodings import done\")\n",
    "\n",
    "## Saving current time for processing time management\n",
    "begintime_whatrast=time.time()\n",
    "\n",
    "## Set computational region to the default region\n",
    "grass.run_command('g.region', flags=\"d\")\n",
    "\n",
    "## For each training point, add the value of the underlying segmentation raster pixel in column \"seg_id\"\n",
    "grass.run_command('v.what.rast', map=\"training_set\", raster=\"segments\",column=\"seg_id\")\n",
    "\n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_whatrast, \"Segment iD added in attribute table of the 'training_set' vector layer in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe with \"seg_id\" and \"class\" of segments in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a [Pandas' dataframe](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) containing only two columns, the segment ID (named 'cat') and class. This dataframe will be used further for joint with the computed statistics of each segment. Please notice that the number of (distinct) segments to be used for training could be different of the number of points in initial training sample, as some points could refer to the same segment depending of the segmentation results.\n",
    "\n",
    "**In the 'columns' parameter, please set only the segment iD and the class to be used in the classification process (only two columns).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a temporary .csv file containing segment iD and class of each training point\n",
    "grass.run_command('v.db.select', overwrite=True,map=\"training_set@CLASSIFICATION\", columns=\"seg_id,Level2\", \\\n",
    "                  file=os.path.join(tempfile.gettempdir(),\"temp_train_segid_class.csv\"),separator=\"comma\")\n",
    "\n",
    "## Import .csv file in a temporary Pandas' dataframe\n",
    "temp=pd.read_csv(os.path.join(tempfile.gettempdir(),\"temp_train_segid_class.csv\"), sep=',',header=0)\n",
    "\n",
    "## Erase the temporary .csv file\n",
    "os.remove(os.path.join(tempfile.gettempdir(),\"temp_train_segid_class.csv\"))\n",
    "\n",
    "## Rename columns \"seg_id\" in \"cat\" for joint further\n",
    "temp.rename(columns={'seg_id': 'cat'}, inplace=True)\n",
    "\n",
    "## Keep only distinct value of column \"cat\"\n",
    "seg_id_class=temp.drop_duplicates(subset='cat', keep=False)\n",
    "\n",
    "## Print\n",
    "print(\"Dataframe created with \"+str(len(seg_id_class))+\" \\\n",
    "      distinct segments'ID for training set from the \"+str(len(temp))+\" point provided in the initial training sample\")\n",
    "\n",
    "## Display table\n",
    "seg_id_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new raster layer with segments to be used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we build a new raster layer containing only segments to be used for training. It will be used after to compute statistics of training objects. \n",
    "\n",
    "This raster is created by reclassifying the original segmentation layer (with segments for the whole area). For that, segments not included in the training set will be replaced with *NULL* values. The ['r.reclass' command](https://grass.osgeo.org/grass72/manuals/r.reclass.html) is used for this purpose. Before reclassification, a 'reclass rule file' containing instructions for reclassification is created.\n",
    "\n",
    "In GRASS GIS, a reclassified raster is only a specific rule assigned to another existing raster. When dealing with very large dataset, display a reclassified raster could be very long. If you want to ensure a faster display of a reclassified raster, you can write a new raster based on the reclassified one. Please note that writing a new raster will use more disk space. The last part of the following cell is dedicated to this purpose. It is optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute reclassification rules and build a raster of training segments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new raster layer with segments to be used for training\n",
    "\n",
    "## Saving current time for processing time management\n",
    "print (\"Bulding a raster map with training segments on \" + time.ctime())\n",
    "begintime_reclassify=time.time()\n",
    "\n",
    "## Define reclass rule\n",
    "rule=\"\"\n",
    "for seg_id in grass.parse_command('v.db.select', map='training_set',columns='seg_id', flags='c'): \n",
    "    #note that parse_command provide a list of DISTINCT values\n",
    "    rule+=str(seg_id)\n",
    "    rule+=\"=\"\n",
    "    rule+=str(seg_id)\n",
    "    rule+=\"\\n\"\n",
    "rule+=\"*\"\n",
    "rule+=\"=\"\n",
    "rule+=\"NULL\"\n",
    "\n",
    "## Create a temporary 'reclass_rule.csv' file\n",
    "outputcsv=os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname,\"reclass_rules.csv\") \n",
    "f = open(outputcsv, 'w')\n",
    "f.write(rule)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set computational region to the default region\n",
    "grass.run_command('g.region', flags=\"d\")\n",
    "\n",
    "outputcsv=os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname,\"reclass_rules.csv\")\n",
    "print(outputcsv)\n",
    "## Reclass segments raster layer to keep only training segments, using the reclas_rule.csv file\n",
    "grass.run_command('r.reclass', overwrite=True, input=\"segments\", output=\"segments_training\", rules=outputcsv)\n",
    "\n",
    "## Create the same raster with r.mapcalc (to ensure fast display)\n",
    "##### Comment the following lines if you want to save disk space instead of fast display\n",
    "formula=\"segments_training_temp=segments_training\"\n",
    "grass.mapcalc(formula, overwrite=True)\n",
    "\n",
    "## Rename the new raster with the name of the original one (will be overwrited)\n",
    "grass.run_command('g.rename', overwrite=True, raster=\"segments_training_temp,segments_training\")\n",
    "\n",
    "# Remove the existing GRASS colortable (for faster display in GRASS map display)\n",
    "grass.run_command('r.colors', flags=\"r\", map=\"segments_training\", color=\"random\")\n",
    "\n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_reclassify, \"Raster map with training segments builted in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute statistics on training segments with i.segment.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use here the ['i.segment.stats' add-on](https://grass.osgeo.org/grass70/manuals/addons/i.segment.stats.html) to compute statistics for each object. As this add-on is not by-default installed, the first cell is there to install it with ['g.extension' command](https://grass.osgeo.org/grass72/manuals/g.extension.html). Another add-on, ['r.object.geometry'](https://grass.osgeo.org/grass70/manuals/addons/r.object.geometry.html) is also installed and is required for computing morphological statistics by i.segment.stats."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Instal i.segment.stats if not yet installed\n",
    "if \"i.segment.stats\" not in grass.parse_command('g.extension', flags=\"a\"):\n",
    "    grass.run_command('g.extension', extension=\"i.segment.stats\")\n",
    "    print \"i.segment.stats have been installed on your computer\"\n",
    "else: print \"i.segment.stats is already installed on your computer\" \n",
    "    \n",
    "## Instal r.object.geometry if not yet installed\n",
    "if \"r.object.geometry\" not in grass.parse_command('g.extension', flags=\"a\"):\n",
    "    grass.run_command('g.extension', extension=\"r.object.geometry\")\n",
    "    print \"r.object.geometry have been installed on your computer\"\n",
    "else: print \"r.object.geometry is already installed on your computer\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set list of raster from which to compute statistics with i.segment.stats**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after, a list of raster layer on which to compute statistics is saved. Please adapt those layers according to the raster you want to use for object statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the name of rasters available in PERMANENT and CLASSIFICATION mapset\n",
    "print (grass.list_strings(\"raster\", mapset=\"PERMANENT\", flag='r'))\n",
    "print (grass.list_strings(\"raster\", mapset=\"CLASSIFICATION\", flag='r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute statistics of segments with i.segment.stats**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, ['i.segment.stats' add-on](https://grass.osgeo.org/grass70/manuals/addons/i.segment.stats.html) is used to compute object statistics. Please refer to the official help if you want to modify the parameters. Other raster statistics and morphological features could be used according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of raster layers for which statistics will be computed\n",
    "inputstats=\"opt_blue@CLASSIFICATION\"\n",
    "inputstats+=\",opt_green@CLASSIFICATION\"\n",
    "inputstats+=\",opt_red@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_idm@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_asm@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_contr@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_corr@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_dv@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_entr@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_se@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_sa@CLASSIFICATION\"\n",
    "inputstats+=\",SLOPE@CLASSIFICATION\"\n",
    "print(inputstats)\n",
    "\n",
    "## Define computational region to match the extention of segmentation raster\n",
    "grass.run_command('g.region', overwrite=True,raster=\"segments@CLASSIFICATION\")\n",
    "\n",
    "## Saving current time for processing time management\n",
    "print(\"Start computing statistics for training segments, using i.segment.stats on \" + time.ctime())\n",
    "begintime_isegmentstats=time.time()\n",
    "\n",
    "grass.run_command('i.segment.stats', overwrite=True,\\\n",
    "                  map=\"segments_training@CLASSIFICATION\", \\\n",
    "                  rasters=inputstats, \\\n",
    "                  raster_statistics=\"min,max,range,mean,stddev,sum,variance,first_quart,median,third_quart\", \\\n",
    "                  area_measures=\"area,perimeter,compact_circle\", \\\n",
    "                  csvfile=r\"XXX\\CLASSIFICATION\\stats_training_sample.csv\",\\\n",
    "                  processes=\"2\")\n",
    "\n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_isegmentstats, \"Segment statistics computed in : \")                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove temporary raster layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove \"segment_training\" raster layer\n",
    "grass.run_command('g.remove', flags=\"f\", type=\"raster\", name=\"segments_training@CLASSIFICATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for unwanted values (Null/Inf values) in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import .csv file\n",
    "temp_stat_train=pd.read_csv(r\"XXX\\CLASSIFICATION\\stats_training_sample.csv\", sep='|',header=0)\n",
    "print (\"The .csv file with results of i.segment.stats for \"+str(len(temp_stat_train))+\" training segments imported in a new dataframe\")\n",
    "temp_stat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for unwanted values (Null/Inf values) in data\n",
    "\n",
    "## Check and count for NaN values by column in the table\n",
    "if temp_stat_train.isnull().any().any():\n",
    "    for colomn in list(temp_stat_train.columns.values):\n",
    "        if temp_stat_train[colomn].isnull().any():\n",
    "            print (\"Column '\"+str(colomn)+\"' have \"+str(temp_stat_train[colomn].isnull().sum())+\" NULL values\")\n",
    "else: print (\"No missing values in dataframe\")\n",
    "\n",
    "## Check and count for Inf values by column in the table\n",
    "if np.isinf(temp_stat_train).any().any():\n",
    "    for colomn in list(temp_stat_train.columns.values):\n",
    "        if np.isinf(temp_stat_train[colomn]).any():\n",
    "            print (\"Column '\"+str(colomn)+\"' have \"+str(np.isinf(temp_stat_train[colomn]).sum())+\" Infinite values\")\n",
    "else: print (\"No infinite values in dataframe\")\n",
    "\n",
    "## Display table\n",
    "temp_stat_train.head()\n",
    "\n",
    "## Check and count for Inf values by column in the table\n",
    "if np.isinf(temp_stat_train).any().any():\n",
    "    for colomn in list(temp_stat_train.columns.values):\n",
    "        if np.isinf(temp_stat_train[colomn]).any():\n",
    "            print (\"Column '\"+str(colomn)+\"' still have \"+str(np.isinf(temp_stat_train[colomn]).sum())+\" Infinite values\")\n",
    "else: print (\"No more infinite values in dataframe\")\n",
    "     \n",
    "## => If NULL values or other problem, open the table and remove manually the problematic lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building final training set table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after, dataframe of training segments' classes with dataframe of training segments' statistics are merged together and saved into a .csv file. This one will be used further in the machine learning classification add-on 'v.class.mlR'. [The merge function of Pandas](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html) is used to perform the joint between dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classvalue = \"Level2\"\n",
    "\n",
    "## Join between tables (pandas dataframe) on column 'cat'\n",
    "training_sample=pd.merge(seg_id_class, temp_stat_train, on='cat')\n",
    "\n",
    "## Check if there are NaN values in the table and print basic information\n",
    "if training_sample.isnull().any().any():\n",
    "    print (\"WARNING: Some values are missing in the dataset\")\n",
    "else:\n",
    "    \n",
    "    # Write dataframe in a .csv file\n",
    "    training_sample.to_csv(path_or_buf=r\"XXX\\CLASSIFICATION\\stats_training_sample.csv\", \\\n",
    "                       sep='|', header=True, quoting=None, decimal='.', index=False)\n",
    "    print (\"A new csv table called 'stats_training_set', \\\n",
    "            to be used for training, have been created with \"+str(len(training_sample))+\" rows.\")\n",
    "\n",
    "## Number of points per class in training sample\n",
    "print (\"Number of segments per class in training sample\\n\")\n",
    "print (training_sample.groupby(Classvalue).size())\n",
    "\n",
    "## Display table\n",
    "training_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute statistics for segments to be classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section uses the ['i.segment.stats' add-on](https://grass.osgeo.org/grass70/manuals/addons/i.segment.stats.html) to compute statistics for each object to be classified.\n",
    "\n",
    "**Please be careful that the statistic you will compute for objects to be classified should be the same as those computed previously for the training set!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Create raster of segments to be classified which are in the image subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define computational region to match the extention of segmentation raster\n",
    "grass.run_command('g.region', overwrite=True,raster=\"opt_red@PERMANENT\")\n",
    "\n",
    "# Create a new raster layer with segments inside the current computational region, using r.map.calc\n",
    "formula=\"segments_to_be_classified=segments@CLASSIFICATION\"\n",
    "grass.mapcalc(formula, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set list of raster from which to compute statistics with i.segment.stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the name of rasters available in PERMANENT and CLASSIFICATION mapset\n",
    "print (grass.read_command('g.list',type=\"raster\", mapset=\"PERMANENT\", flags='rp'))\n",
    "print (grass.read_command('g.list',type=\"raster\", mapset=\"CLASSIFICATION\", flags='rp'))\n",
    "print (grass.read_command('g.list',type=\"vector\", mapset=\"CLASSIFICATION\", flags='rp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of raster layers for which statistics will be computed\n",
    "inputstats=\"opt_blue@CLASSIFICATION\"\n",
    "inputstats+=\",opt_green@CLASSIFICATION\"\n",
    "inputstats+=\",opt_red@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_idm@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_asm@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_contr@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_corr@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_dv@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_entr@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_se@CLASSIFICATION\"\n",
    "inputstats+=\",texture_P_sa@CLASSIFICATION\"\n",
    "inputstats+=\",SLOPE@CLASSIFICATION\"\n",
    "print(inputstats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute statistics of segments to be classified (with i.segment.stats)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "print(\"Start computing statistics for training segments, using i.segment.stats on \" + time.ctime())\n",
    "begintime_isegmentstats=time.time()\n",
    "\n",
    "## Compute statistics of objets using i.segment.stats only with .csv output (no vectormap output)\n",
    "outputcsv=os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname,\"stats_segments.csv\")\n",
    "print(outputcsv)\n",
    "\n",
    "grass.run_command('i.segment.stats', overwrite=True, \\\n",
    "                  map=\"segments_to_be_classified@CLASSIFICATION\", \\\n",
    "                  rasters=inputstats, \\\n",
    "                  raster_statistics=\"min,max,range,mean,stddev,sum,variance,first_quart,median,third_quart\", \\\n",
    "                  area_measures=\"area,perimeter,compact_circle\", \\\n",
    "                  csvfile=outputcsv, \\\n",
    "                  processes=\"2\")\n",
    "\n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_isegmentstats, \"Segment statistics computed in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import .csv file\n",
    "temp_stat_train=pd.read_csv(r\"XXX\\CLASSIFICATION\\stats_segments.csv\", sep='|',header=0)\n",
    "temp_stat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove \"segment_training\" raster layer\n",
    "grass.run_command('g.remove', flags=\"f\", type=\"raster\", name=\"segments_to_be_classified@CLASSIFICATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import .csv file\n",
    "stats_segments=pd.read_csv(r\"XXX\\CLASSIFICATION\\stats_segments.csv\", sep='|',header=0)\n",
    "print (\"The .csv file with results of i.segment.stats for the \"+str(len(stats_segments))+\" segments to be classified imported in a new dataframe\")\n",
    "\n",
    "## Check and count for NaN values by column in the table\n",
    "if stats_segments.isnull().any().any():\n",
    "    for colomn in list(stats_segments.columns.values):\n",
    "        if stats_segments[colomn].isnull().any():\n",
    "            print (\"Column '\"+str(colomn)+\"' have \"+str(stats_segments[colomn].isnull().sum())+\" NULL values\")\n",
    "else: print (\"No missing values in dataframe\")\n",
    "        \n",
    "## Check and count for Inf values by column in the table\n",
    "if np.isinf(stats_segments).any().any():\n",
    "    for colomn in list(stats_segments.columns.values):\n",
    "        if np.isinf(stats_segments[colomn]).any():\n",
    "            print (\"Column '\"+str(colomn)+\"' have \"+str(np.isinf(stats_segments[colomn]).sum())+\" Infinite values\")\n",
    "else: print (\"No infinite values in dataframe\")\n",
    "\n",
    "## Check and count for Inf values by column in the table\n",
    "if np.isinf(stats_segments).any().any():\n",
    "    for colomn in list(stats_segments.columns.values):\n",
    "        if np.isinf(stats_segments[colomn]).any():\n",
    "            print (\"Column '\"+str(colomn)+\"' still have \"+str(np.isinf(stats_segments[colomn]).sum())+\" Infinite values\")\n",
    "else: print (\"No infinite values in dataframe\")\n",
    "            \n",
    "## Display table\n",
    "stats_segments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving current time for processing time management\n",
    "print (\"Start classification process, using v.class.mlR on \" + time.ctime())\n",
    "begintime_vclassmlr=time.time()\n",
    "\n",
    "## Erase temporary files no more needed\n",
    "grass.run_command('g.remove', flags=\"rf\", type=\"raster\", pattern=\"indiv_classification\")\n",
    "\n",
    "# Classification using v.class.mlR\n",
    "grass.run_command('v.class.mlR', flags=\"fip\", overwrite=True, \\\n",
    "                  segments_file=r\"XXX\\CLASSIFICATION\\stats_segments.csv\", \\\n",
    "                  training_file=r\"XXX\\CLASSIFICATION\\stats_training_sample.csv\", \\\n",
    "                  raster_segments_map=\"segments@CLASSIFICATION\", \\\n",
    "                  classified_map=\"indiv_classification_fs\", \\\n",
    "                  train_class_column=\"Level2\", \\\n",
    "                  output_class_column=\"vote\", \\\n",
    "                  output_prob_column=\"prob\", \\\n",
    "                  max_features=\"100\", \\\n",
    "                  classifiers=\"rf\", \\\n",
    "                  folds=\"10\", \\\n",
    "                  partitions=\"10\", \\\n",
    "                  tunelength=\"10\", \\\n",
    "                  weighting_modes=\"smv,swv,bwwv,qbwwv\", \\\n",
    "                  weighting_metric=\"accuracy\", \\\n",
    "                  classification_results=r\"XXX\\CLASSIFICATION\\all_results.csv\", \\\n",
    "                  variable_importance_file=r\"XXX\\CLASSIFICATION\\variables_importance.txt\", \\\n",
    "                  accuracy_file=r\"XXX\\CLASSIFICATION\\accuracy.csv\", \\\n",
    "                  model_details=r\"XXX\\CLASSIFICATION\\classifier_runs.txt\", \\\n",
    "                  bw_plot_file=r\"XXX\\CLASSIFICATION\\box_whisker\", \\\n",
    "                  r_script_file=r\"XXX\\CLASSIFICATION\\Rscript_mlR.R\", \\\n",
    "                  processes=\"2\")\n",
    "\n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_vclassmlr, \"Classification process achieved in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import .csv file\n",
    "accuracy=pd.read_csv(r\"XXX\\CLASSIFICATION\\accuracy.csv\", sep=',',header=0)\n",
    "## Display table\n",
    "accuracy.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open file\n",
    "classifier_runs = open(r\"XXX\\CLASSIFICATION\\classifier_runs.txt\", 'r')\n",
    "## Read file\n",
    "print (classifier_runs.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the list of raster available in the current mapset\n",
    "print (grass.read_command('g.list', type=\"raster\", mapset=\"CLASSIFICATION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a copy of the classified maps at level 2 for a faster display in GRASS GIS\n",
    "## Saving current time for processing time management\n",
    "print (\"Making a copy of classified maps in current mapset on \" + time.ctime())\n",
    "begintime_copyraster=time.time()\n",
    "\n",
    "for classif in grass.list_strings(\"rast\", pattern=\"indiv_\", flag='r') : \n",
    "    print (classif)\n",
    "    \n",
    "    ## Create the same raster with r.mapcalc\n",
    "    formula=str(classif[:-15])+\"_01=\"+str(classif[:-15])\n",
    "    print (formula)\n",
    "    grass.mapcalc(formula, overwrite=True)\n",
    "    print (\"mapcalc performed\")\n",
    "    \n",
    "    ## Rename the new raster with the name of the original one (will be overwrited)\n",
    "    renameformula=str(classif[:-15])+\"_01,\"+str(classif[:-15])\n",
    "    grass.run_command('g.rename', overwrite=True, raster=renameformula)\n",
    "    print (renameformula)  \n",
    "    \n",
    "    ## Define color table. Replace with the RGB values of wanted colors of each class\n",
    "    color_table=\"11 0:128:0\"+\"\\n\"\n",
    "    color_table+=\"12 233:241:8\"+\"\\n\"\n",
    "    color_table+=\"21 189:193:255\"+\"\\n\"\n",
    "    color_table+=\"31 243:220:164\"+\"\\n\"\n",
    "    color_table+=\"32 161:118:12\"+\"\\n\"\n",
    "    color_table+=\"33 94:71:13\"+\"\\n\"\n",
    "    color_table+=\"41 191:191:191\"+\"\\n\"\n",
    "    color_table+=\"42 0:0:0\"+\"\\n\"\n",
    "    color_table+=\"43 255:255:255\"+\"\\n\"\n",
    "    print(\"Color table defined\")\n",
    "    \n",
    "    ## Create a temporary 'color_table.txt' file\n",
    "    outputcsv=r\"XXX\\CLASSIFICATION\\temp_color_table.txt\" \n",
    "    \n",
    "    ## Define the csv output file name\n",
    "    f = open(outputcsv, 'w')\n",
    "    f.write(color_table)\n",
    "    f.close()\n",
    "    print (\"outputcsv defined\")\n",
    "    \n",
    "    ## Apply new color the existing GRASS colortable (for faster display in GRASS map display)\n",
    "    grass.run_command('r.colors', map=classif, rules=outputcsv)\n",
    "    print (\"New colors applied\")\n",
    "    \n",
    "    ## Erase the temporary 'color_table.txt' file\n",
    "    os.remove(r\"E:\\CETEO\\GRASS_PAPIER\\Hallembaye\\CLASSIFICATION\\temp_color_table.txt\")\n",
    "    print (\"Temp color file removed\")\n",
    "    \n",
    "    ## Filtering, window 7x7, majority\n",
    "    inputname=\"\"+str(classif[:-15]) \n",
    "    resultname=\"\"+str(classif[:-15])+\"_F7\"\n",
    "    print(resultname)\n",
    "    grass.run_command('r.neighbors', input=classif, output=resultname, method=\"mode\", size=7, overwrite=True)\n",
    "    print(classif, \" has been filtered with 7x7 window as \", resultname)\n",
    "    \n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_copyraster, \"Classified raster maps have been copied in current mapset in \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "print (\"Export classified raster maps on \" + time.ctime())\n",
    "begintime_exportraster=time.time()\n",
    "\n",
    "for classif in grass.list_strings(\"rast\", pattern=\"indiv_\", flag='r'):\n",
    "    outputname=\"XXX\\\\CLASSIFICATION\\\\\"+str(classif[21:-15])+'.tif'\n",
    "    grass.run_command('r.out.gdal', overwrite=True, input=classif, output=outputname, format='GTiff')\n",
    "    print(\"> \",classif,\" exported in \", outputname)\n",
    "    \n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_exportraster, \"Classified raster maps exported in \")\n",
    "                      \n",
    "#print(\"The script ends at \"+ time.ctime())\n",
    "#print_processing_time(begintime_classif_full, \"Entire process has been achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**\n",
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Launch GRASS GIS working session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the name of the mapset in which to work\n",
    "mapsetname=user[\"classification_mapsetname\"]\n",
    "\n",
    "## Launch GRASS GIS working session in the mapset\n",
    "if os.path.exists(os.path.join(user[\"gisdb\"],user[\"location\"],mapsetname)):\n",
    "    gsetup.init(os.environ['GISBASE'], user[\"gisdb\"], user[\"location\"], mapsetname)\n",
    "    print (\"You are now working in mapset '\"+mapsetname+\"'\")\n",
    "else:\n",
    "    print (\"'\"+mapsetname+\"' mapset doesn't exists in \"+user[\"gisdb\"])\n",
    "\n",
    "## Saving current time for processing time management\n",
    "begintime_perform=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation initiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set computational region\n",
    "grass.run_command('g.region', overwrite=True, raster=\"segments\")\n",
    "\n",
    "## Create temporary .csv file with columns of \"test_set\" vector layer\n",
    "grass.run_command('v.db.select', overwrite=True, map=\"test_set@CLASSIFICATION\",\n",
    "file=r\"XXX\\CLASSIFICATION\\test_set.csv\",separator=\"comma\")\n",
    "\n",
    "## Import .csv file into Jupyter notebook (with panda)\n",
    "validation_samples_attributes=pd.read_csv(r\"XXX\\CLASSIFICATION\\test_set.csv\", sep=',',header=0)\n",
    "print( str(len(validation_samples_attributes))+\" points in sample layer imported\")\n",
    "\n",
    "## Delete temporary .csv file\n",
    "os.remove(r\"XXX\\CLASSIFICATION\\test_set.csv\")\n",
    "\n",
    "## Display table\n",
    "validation_samples_attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of points per class in validation sample\n",
    "Classvalue=\"Level2\"\n",
    "print (\"Number of points per class in validation sample\\n\")\n",
    "print (validation_samples_attributes.groupby(Classvalue).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_whatrast=time.time()\n",
    "## Initialize a empty list\n",
    "allclassif=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through all individual classification results\n",
    "for classif in grass.list_strings(\"rast\", pattern=\"indiv_classification_\", flag='r'):\n",
    "    nameclassif=str(classif[21:-15]) # Save the name of classifier\n",
    "    allclassif.append(nameclassif) # Add the name of classifier in the list\n",
    "\n",
    "    ## Add a \"int\" column in test_set layer, for each classification result\n",
    "    grass.run_command('v.db.addcolumn', map=\"test_set\", columns=nameclassif+\" int\")\n",
    "\n",
    "    ## For each validation point, add the value of the underlying classifier raster pixel in column \"seg_id\"\n",
    "    grass.run_command('v.what.rast', map=\"test_set\", \\\n",
    "                  raster=\"indiv_classification_\"+nameclassif+\"@CLASSIFICATION\", \\\n",
    "                  column=nameclassif)\n",
    "\n",
    "## Compute processing time and print it\n",
    "print(\"Predicted classes for '\"+', '.join(allclassif)+\"' added in the 'test_set' layer\")\n",
    "print_processing_time(begintime_whatrast, \"Prossess achieved in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export 'test_set' vector layer attribute table in .csv file.\n",
    "Classvalue=\"Level2\"\n",
    "columnstoexport=str(Classvalue)+\",\"\n",
    "columnstoexport+=', '.join(allclassif)\n",
    "grass.run_command('v.db.select', overwrite=True, map=\"test_set@CLASSIFICATION\", columns=columnstoexport, \\\n",
    "                  file=r\"XXX\\CLASSIFICATION\\predicted_gtruth.csv\",separator=\"comma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create inputs for classification perfomance evaluation (Level-2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define computational region to match the extention of segmentation raster\n",
    "grass.run_command('g.region', overwrite=True, raster=\"segments@CLASSIFICATION\")\n",
    "\n",
    "Classvalue=\"Level2\"\n",
    "\n",
    "## Create raster layers with one pixel corresponding to each object. Pixels values representing either the ground thruth or the prediction of a specific classifier\n",
    "grass.run_command('v.to.rast', overwrite=True, input='test_set',\\\n",
    "                  output='PE_L2_Classvalue', \\\n",
    "                  use='attr', \\\n",
    "                  attribute_column=Classvalue)\n",
    "\n",
    "for result in allclassif:\n",
    "    outputname=\"PE_L2_\"+str(result)\n",
    "    grass.run_command('v.to.rast', overwrite=True, input='test_set',\\\n",
    "                      output=outputname, \\\n",
    "                      use='attr', \\\n",
    "                      attribute_column=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving current time for processing time management\n",
    "begintime_kappa_L2=time.time()\n",
    "\n",
    "## Classification perfomance evalutation using r.kappa (compute per-class kappa)\n",
    "for result in grass.list_strings('rast', pattern=\"PE_L2\", flag=\"r\", exclude=\"PE_L2_Classvalue\"):\n",
    "    outputfile=r\"E:\\CETEO\\GRASS_PAPIER\\Hallembaye\\CLASSIFICATION\\rkappa_\"+str(result[3:-15])+\".txt\"\n",
    "    grass.run_command('r.kappa', flags=\"w\", overwrite=True,\\\n",
    "                      classification=result,\\\n",
    "                      reference=\"PE_L2_Classvalue\",\\\n",
    "                      output=outputfile)\n",
    "    \n",
    "## Compute processing time and print it\n",
    "print_processing_time(begintime_kappa_L2, \"Performance evaluation for Level 2 achieved in :\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Erase temporary files no more needed\n",
    "grass.run_command('g.remove', flags=\"rf\", type=\"raster\", pattern=\"PE_\")\n",
    "grass.run_command('g.remove', flags=\"rf\", type=\"raster\", pattern=\"indiv_classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The script ends at \"+ time.ctime())\n",
    "print_processing_time(begintime_perform, \"Entire process has been achieved in \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The script ends at \"+ time.ctime())\n",
    "print_processing_time(begintime_full,\"Entire process has been achieved in \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**\n",
    "**-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
